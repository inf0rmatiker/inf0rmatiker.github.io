= Installing Kubernetes

== OpenSUSE Leap 15.3

Original documentation for how to install `kubeadm`: https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/install-kubeadm/

. Open these ports on the firewall: https://kubernetes.io/docs/reference/ports-and-protocols/
a. `firewall-cmd --add-port=6443/tcp --permanent`
b. Repeat for all required ports
. Install `conntrack`: `zypper install conntrack-tools`
. Install `socat`: `zypper install socat`
. Enable `ip_forward`: `echo 1 | sudo tee /proc/sys/net/ipv4/ip_forward`
 ** Follow this guide: https://kubernetes.io/docs/setup/production-environment/container-runtimes/#forwarding-ipv4-and-letting-iptables-see-bridged-traffic
. Install `containerd` as the container runtime: Follow instructions on https://github.com/containerd/containerd/blob/main/docs/getting-started.md[containerd's Getting Started page]
 ** Go get runc and CNI plugin files (see following steps)
 ** Go get the https://github.com/containerd/containerd/releases[latest released containerd archive]
 ** Untar it to `/usr/local`: `tar Cxzvf /usr/local containerd-1.6.6-linux-amd64.tar.gz`
 ** Download https://github.com/containerd/containerd/blob/main/containerd.service[containerd.service] and copy it to `/usr/lib/systemd/system/containerd.service` (Official docs say to put it at `/usr/local/lib`, there's nothing there and this won't work. Put it in `/usr/lib/â€¦`)
 ** Launch systemd daemon for containerd:
  *** `systemctl daemon-reload`
  *** `systemctl enable --now containerd`
 ** Get runc archive if you don't already have it: https://github.com/opencontainers/runc/releases
 ** Install it: `install -m 755 runc.amd64 /usr/local/sbin/runc`
 ** Go get CNI plugins: https://github.com/containernetworking/plugins/releases, and install them under `opt/cni/bin`:
  *** `mkdir -p /opt/cni/bin`
  *** `tar Cxzvf /opt/cni/bin cni-plugins-linux-amd64-v1.1.1.tgz`
 ** Check it works by running `ctr --help`
 ** Generate default containerd daemon configuration: `containerd config default > /etc/containerd/config.toml`
. Configure systemd as cgroup with runc:
 ** Edit `/etc/containerd/config.toml`:
+
----
   [plugins."io.containerd.grpc.v1.cri".containerd.runtimes.runc]
       ...
       [plugins."io.containerd.grpc.v1.cri".containerd.runtimes.runc.options]
       SystemdCgroup = true
----

 ** Restart containerd: `sudo systemctl restart containerd`
. Install `kubeadm`: https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/install-kubeadm/
. Install `critcl`:
+
[,bash]
----
 DOWNLOAD_DIR=/usr/local/bin
 sudo mkdir -p $DOWNLOAD_DIR
 VERSION="v1.24.2"
 wget https://github.com/kubernetes-sigs/cri-tools/releases/download/$VERSION/crictl-$VERSION-linux-amd64.tar.gz
 sudo tar zxvf crictl-$VERSION-linux-amd64.tar.gz -C /usr/local/bin
 rm -f crictl-$VERSION-linux-amd64.tar.gz
----

. Install `kubeadm`, `kubectl`, `kubelet`
+
[,bash]
----
 RELEASE="$(curl -sSL https://dl.k8s.io/release/stable.txt)"`
 ARCH="amd64"
 cd $DOWNLOAD_DIR
 sudo curl -L --remote-name-all https://storage.googleapis.com/kubernetes-release/release/${RELEASE}/bin/linux/${ARCH}/{kubeadm,kubelet,kubectl}
 sudo chmod +x {kubeadm,kubelet,kubectl}
 RELEASE_VERSION="v0.4.0"
 curl -sSL "https://raw.githubusercontent.com/kubernetes/release/${RELEASE_VERSION}/cmd/kubepkg/templates/latest/deb/kubelet/lib/systemd/system/kubelet.service" | sed "s:/usr/bin:${DOWNLOAD_DIR}:g" | sudo tee /etc/systemd/system/kubelet.service
 sudo mkdir -p /etc/systemd/system/kubelet.service.d
 curl -sSL "https://raw.githubusercontent.com/kubernetes/release/${RELEASE_VERSION}/cmd/kubepkg/templates/latest/deb/kubeadm/10-kubeadm.conf" | sed "s:/usr/bin:${DOWNLOAD_DIR}:g" | sudo tee /etc/systemd/system/kubelet.service.d/10-kubeadm.conf
----

. Enable kubelet: `systemctl enable --now kubelet`

[,bash]
----
Your Kubernetes control-plane has initialized successfully!

To start using your cluster, you need to run the following as a regular user:

 mkdir -p $HOME/.kube
 sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
 sudo chown $(id -u):$(id -g) $HOME/.kube/config

Alternatively, if you are the root user, you can run:

 export KUBECONFIG=/etc/kubernetes/admin.conf
----

. You should now deploy a pod network to the cluster.
 ** Run `kubectl apply -f <podnetwork>.yaml` with one of the options listed at: https://kubernetes.io/docs/concepts/cluster-administration/addons/
. Then you can join any number of worker nodes by running the following on each as `root`:

[,bash]
----
kubeadm join 172.26.143.70:6443 --token oos4yr.46zwgo9mzqavckkx --discovery-token-ca-cert-hash sha256:2b725a2cda814b07ee07c9d704de5a5cc2451c746eeb5b32277ebe661b9a36e4
----

== Rocky Linux 9.5

This example install will be on the `mawenzi` cluster, using `mawenzi-01` as the admin node.

We're gonna be doing this the hard way, without help from `kubeadm`.

=== References

* https://docs.rockylinux.org/labs/kubernetes-the-hard-way/lab0-README/[Rocky: Kubernetes the Hard Way]
* https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/[Kubernetes: Bootstrapping a cluster with kubeadm]
** https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/install-kubeadm/[Installing kubeadm]
* https://kubernetes.io/docs/concepts/overview/components/[Kubernetes: Components]

=== Prerequisites

*Proxies*:

Set up DNF HPE proxy so we can download things with DNF from the internet.

[,bash]
----
cat >> /etc/dnf/dnf.conf << EOF
[main]
gpgcheck=0
installonly_limit=3
clean_requirements_on_remove=True
best=True
skip_if_unavailable=False
proxy=http://proxy.houston.hpecorp.net:8080
EOF
----

Set up HTTP HPE proxy so we can download things with `wget`, etc, from the internet.

[,bash]
----
cat >> /etc/environment << EOF
http_proxy="http://proxy.houston.hpecorp.net:8080/"
https_proxy="http://proxy.houston.hpecorp.net:8080/"
ftp_proxy="http://proxy.houston.hpecorp.net:8080/"
no_proxy="admin,localhost,127.0.0.1,.us.cray.com,.hpe.com"
EOF
----

Upgrade as many packages, and the kernel with DNF as we can before we get started:

[,bash]
----
dnf upgrade
----

Download basic CLI utilities

[,bash]
----
dnf -y install wget curl vim openssl git
----

=== Download binaries

https://docs.rockylinux.org/labs/kubernetes-the-hard-way/lab2-jumpbox/#download-binaries

Make a Downloads directory

[,console]
----
[root@mawenzi-01 ~]# mkdir downloads
[root@mawenzi-01 ~]# cd downloads/
----

Create a script to help download all the binary components needed for the cluster.
Adjust the versions based on the most recent released versions of things.
These are the versions we're using for this example.

.download.sh
[,bash]
----
#!/bin/bash

# https://kubernetes.io/releases/
KUBERNETES_VERSION="v1.33.0"

# https://github.com/opencontainers/runc/releases
RUNC_VERSION="v1.3.0"

# https://github.com/kubernetes-sigs/cri-tools/releases
CRI_TOOLS_VERSION="v1.33.0"

# https://github.com/containernetworking/plugins/releases
CNI_PLUGINS_VERSION="v1.7.1"

# https://github.com/containerd/containerd/releases
CONTAINERD_VERSION="2.1.4"

# https://github.com/etcd-io/etcd/releases/
ETCD_VERSION="v3.6.4"

download_urls=(
	https://dl.k8s.io/$KUBERNETES_VERSION/bin/linux/amd64/kubectl
	https://dl.k8s.io/$KUBERNETES_VERSION/bin/linux/amd64/kube-apiserver
	https://dl.k8s.io/$KUBERNETES_VERSION/bin/linux/amd64/kube-controller-manager
	https://dl.k8s.io/$KUBERNETES_VERSION/bin/linux/amd64/kube-scheduler
	https://dl.k8s.io/$KUBERNETES_VERSION/bin/linux/amd64/kube-proxy
	https://dl.k8s.io/$KUBERNETES_VERSION/bin/linux/amd64/kubelet
	https://github.com/kubernetes-sigs/cri-tools/releases/download/$CRI_TOOLS_VERSION/crictl-$CRI_TOOLS_VERSION-linux-amd64.tar.gz
	https://github.com/opencontainers/runc/releases/download/$RUNC_VERSION/runc.amd64
	https://github.com/containernetworking/plugins/releases/download/$CNI_PLUGINS_VERSION/cni-plugins-linux-amd64-$CNI_PLUGINS_VERSION.tgz
	https://github.com/containerd/containerd/releases/download/v$CONTAINERD_VERSION/containerd-$CONTAINERD_VERSION-linux-amd64.tar.gz
	https://github.com/etcd-io/etcd/releases/download/$ETCD_VERSION/etcd-$ETCD_VERSION-linux-amd64.tar.gz
)

for download_url in "${download_urls[@]}"; do
	wget -q --show-progress  --https-only --timestamping "$download_url"
done

----

Execute the script (after `chmod +x download.sh`):

[,console]
----
[root@mawenzi-01 Downloads]# ./download.sh
kubectl                                    100%[=======================================================================================>]  57.34M  29.8MB/s    in 1.9s
kube-apiserver                             100%[=======================================================================================>]  93.42M  23.2MB/s    in 4.1s
kube-controller-manager                    100%[=======================================================================================>]  86.55M  21.2MB/s    in 4.2s
kube-scheduler                             100%[=======================================================================================>]  66.38M  23.5MB/s    in 2.8s
kube-proxy                                 100%[=======================================================================================>]  67.32M  20.2MB/s    in 3.3s
kubelet                                    100%[=======================================================================================>]  77.91M  28.5MB/s    in 2.7s
crictl-v1.33.0-linux-amd64.tar.gz          100%[=======================================================================================>]  19.43M  16.0MB/s    in 1.2s
runc.amd64                                 100%[=======================================================================================>]  11.31M  13.0MB/s    in 0.9s
cni-plugins-linux-amd64-v1.7.1.tgz         100%[=======================================================================================>]  53.31M  17.2MB/s    in 3.1s
containerd-2.1.4-linux-amd64.tar.gz        100%[=======================================================================================>]  31.67M  14.0MB/s    in 2.3s
etcd-v3.6.4-linux-amd64.tar.gz             100%[=======================================================================================>]  22.53M  13.4MB/s    in 1.7s
----

Make the binaries executable: `chmod +x kube* runc.amd64`.

=== Install kubectl

https://docs.rockylinux.org/labs/kubernetes-the-hard-way/lab2-jumpbox/#install-kubectl

[,bash]
----
cp kubectl /usr/local/bin/
----

Verify version:

[,console]
----
[root@mawenzi-01 Downloads]# kubectl version --client
Client Version: v1.33.0
Kustomize Version: v5.6.0
----

=== Set up machines file

https://docs.rockylinux.org/labs/kubernetes-the-hard-way/lab3-compute-resources/#machine-database

Create a `machines.txt` file with the format: `IPV4_ADDRESS FQDN HOSTNAME POD_SUBNET`.

Each column corresponds to a machine IP address `IPV4_ADDRESS`, fully qualified domain name `FQDN`,
host name `HOSTNAME`, and the IP subnet `POD_SUBNET`. Kubernetes assigns one IP address per pod,
and the `POD_SUBNET` represents the unique IP address range assigned to each machine in the cluster for doing so.

.machines.txt
[,console]
----
10.214.134.147 mawenzi-01.hpc.amslabs.hpecorp.net mawenzi-01
10.214.130.159 mawenzi-02.hpc.amslabs.hpecorp.net mawenzi-02 10.200.0.0/24
10.214.134.195 mawenzi-03.hpc.amslabs.hpecorp.net mawenzi-03 10.200.0.1/24
----

=== Set up worker nodes SSH access

With a blank install, you won't have any SSH keys generated:

[,console]
----
[root@mawenzi-01 kubernetes]# ls -la ~/.ssh
total 16
drwx------. 2 root root   71 Aug 22 11:57 .
dr-xr-x---. 5 root root 4096 Aug 22 11:53 ..
-rw-------. 1 root root  195 Aug 22 10:02 authorized_keys
-rw-------. 1 root root  828 Aug 22 11:57 known_hosts
-rw-r--r--. 1 root root   92 Aug 22 11:57 known_hosts.old
----

Use `ssh-keygen` to generate a public/private key pair.

Copy the public key to each node in the `machines.txt` file.

[,bash]
-----
while read IP FQDN HOST SUBNET; do
  ssh-copy-id root@${IP}
done < machines.txt
-----

[,console]
----
[root@mawenzi-01 kubernetes]# ssh-keygen
Generating public/private rsa key pair.
Enter file in which to save the key (/root/.ssh/id_rsa):
Enter passphrase (empty for no passphrase):
Enter same passphrase again:
Your identification has been saved in /root/.ssh/id_rsa
Your public key has been saved in /root/.ssh/id_rsa.pub
The key fingerprint is:
SHA256:QxH4vc8bmPmzyAKa+HPk0nUsnRPdXIf51fBJx98zO0c root@mawenzi-01
The key's randomart image is:
+---[RSA 3072]----+
|       .o.    .*o|
|      .  .    +.O|
|       ... . o +*|
|       .. o . ooE|
|        So +   .+|
|      o o.B+   o.|
|   . * o o++.   o|
|  . = + .. o+.   |
|   ..+   .o ++   |
+----[SHA256]-----+
----

=== Set up hostnames

https://docs.rockylinux.org/labs/kubernetes-the-hard-way/lab3-compute-resources/#hostnames

N/A: We already have hostnames from the lab so maybe we don't need to do this?

=== Provision a CA and TLS certificates

https://docs.rockylinux.org/labs/kubernetes-the-hard-way/lab4-certificate-authority/

In this lab, you will provision a PKI Infrastructure using OpenSSL to bootstrap a Certificate Authority and generate TLS certificates for the following components:

* kube-apiserver
* kube-controller-manager
* kube-scheduler
* kubelet
* kube-proxy

In this section, you will provision a Certificate Authority that you will use to generate additional
TLS certificates for the other Kubernetes components. Setting up CA and generating certificates with
openssl can be time-consuming, especially when doing it for the first time.
To streamline this lab, an openssl configuration file, `ca.conf`, must be included,
which defines all the details needed to generate certificates for each Kubernetes component.

We'll use the following `ca.conf` Certificate Authority configuration file:

.ca.conf
[,text]
----
[req]
distinguished_name = req_distinguished_name
prompt             = no
x509_extensions    = ca_x509_extensions

[ca_x509_extensions]
basicConstraints = CA:TRUE
keyUsage         = cRLSign, keyCertSign

[req_distinguished_name]
C   = US
ST  = Colorado
L   = Denver
CN  = CA

[admin]
distinguished_name = admin_distinguished_name
prompt             = no
req_extensions     = default_req_extensions

[admin_distinguished_name]
CN = admin
O  = system:masters

# Service Accounts
#
# The Kubernetes Controller Manager leverages a key pair to generate
# and sign service account tokens as described in the
# [managing service accounts](https://kubernetes.io/docs/admin/service-accounts-admin/)
# documentation.

[service-accounts]
distinguished_name = service-accounts_distinguished_name
prompt             = no
req_extensions     = default_req_extensions

[service-accounts_distinguished_name]
CN = service-accounts

# Worker Nodes
#
# Kubernetes uses a [special-purpose authorization mode](https://kubernetes.io/docs/admin/authorization/node/)
# called Node Authorizer, that specifically authorizes API requests made
# by [Kubelets](https://kubernetes.io/docs/concepts/overview/components/#kubelet).
# In order to be authorized by the Node Authorizer, Kubelets must use a credential
# that identifies them as being in the `system:nodes` group, with a username
# of `system:node:<nodeName>`.
[mawenzi-02]
distinguished_name = mawenzi-02_distinguished_name
prompt             = no
req_extensions     = mawenzi-02_req_extensions

[mawenzi-02_req_extensions]
basicConstraints     = CA:FALSE
extendedKeyUsage     = clientAuth, serverAuth
keyUsage             = critical, digitalSignature, keyEncipherment
nsCertType           = client
nsComment            = "mawenzi-02 Certificate"
subjectAltName       = DNS:mawenzi-02, IP:127.0.0.1
subjectKeyIdentifier = hash

[mawenzi-02_distinguished_name]
CN = system:node:mawenzi-02
O  = system:nodes
C  = US
ST = Colorado
L  = Denver

[mawenzi-03]
distinguished_name = mawenzi-03_distinguished_name
prompt             = no
req_extensions     = mawenzi-03_req_extensions

[mawenzi-03_req_extensions]
basicConstraints     = CA:FALSE
extendedKeyUsage     = clientAuth, serverAuth
keyUsage             = critical, digitalSignature, keyEncipherment
nsCertType           = client
nsComment            = "mawenzi-03 Certificate"
subjectAltName       = DNS:mawenzi-03, IP:127.0.0.1
subjectKeyIdentifier = hash

[mawenzi-03_distinguished_name]
CN = system:node:mawenzi-03
O  = system:nodes
C  = US
ST = Colorado
L  = Denver


# Kube Proxy Section
[kube-proxy]
distinguished_name = kube-proxy_distinguished_name
prompt             = no
req_extensions     = kube-proxy_req_extensions

[kube-proxy_req_extensions]
basicConstraints     = CA:FALSE
extendedKeyUsage     = clientAuth, serverAuth
keyUsage             = critical, digitalSignature, keyEncipherment
nsCertType           = client
nsComment            = "Kube Proxy Certificate"
subjectAltName       = DNS:kube-proxy, IP:127.0.0.1
subjectKeyIdentifier = hash

[kube-proxy_distinguished_name]
CN = system:kube-proxy
O  = system:node-proxier
C  = US
ST = Colorado
L  = Denver


# Controller Manager
[kube-controller-manager]
distinguished_name = kube-controller-manager_distinguished_name
prompt             = no
req_extensions     = kube-controller-manager_req_extensions

[kube-controller-manager_req_extensions]
basicConstraints     = CA:FALSE
extendedKeyUsage     = clientAuth, serverAuth
keyUsage             = critical, digitalSignature, keyEncipherment
nsCertType           = client
nsComment            = "Kube Controller Manager Certificate"
subjectAltName       = DNS:kube-proxy, IP:127.0.0.1
subjectKeyIdentifier = hash

[kube-controller-manager_distinguished_name]
CN = system:kube-controller-manager
O  = system:kube-controller-manager
C  = US
ST = Colorado
L  = Denver

# Scheduler
[kube-scheduler]
distinguished_name = kube-scheduler_distinguished_name
prompt             = no
req_extensions     = kube-scheduler_req_extensions

[kube-scheduler_req_extensions]
basicConstraints     = CA:FALSE
extendedKeyUsage     = clientAuth, serverAuth
keyUsage             = critical, digitalSignature, keyEncipherment
nsCertType           = client
nsComment            = "Kube Scheduler Certificate"
subjectAltName       = DNS:kube-scheduler, IP:127.0.0.1
subjectKeyIdentifier = hash

[kube-scheduler_distinguished_name]
CN = system:kube-scheduler
O  = system:system:kube-scheduler
C  = US
ST = Colorado
L  = Denver


# API Server
#
# The Kubernetes API server is automatically assigned the `kubernetes`
# internal dns name, which will be linked to the first IP address (`10.32.0.1`)
# from the address range (`10.32.0.0/24`) reserved for internal cluster
# services.

[kube-api-server]
distinguished_name = kube-api-server_distinguished_name
prompt             = no
req_extensions     = kube-api-server_req_extensions

[kube-api-server_req_extensions]
basicConstraints     = CA:FALSE
extendedKeyUsage     = clientAuth, serverAuth
keyUsage             = critical, digitalSignature, keyEncipherment
nsCertType           = client
nsComment            = "Kube Scheduler Certificate"
subjectAltName       = @kube-api-server_alt_names
subjectKeyIdentifier = hash

[kube-api-server_alt_names]
IP.0  = 127.0.0.1
IP.1  = 10.32.0.1
DNS.0 = kubernetes
DNS.1 = kubernetes.default
DNS.2 = kubernetes.default.svc
DNS.3 = kubernetes.default.svc.cluster
DNS.4 = kubernetes.svc.cluster.local
DNS.5 = server.kubernetes.local
DNS.6 = api-server.kubernetes.local

[kube-api-server_distinguished_name]
CN = kubernetes
C  = US
ST = Colorado
L  = Denver


[default_req_extensions]
basicConstraints     = CA:FALSE
extendedKeyUsage     = clientAuth
keyUsage             = critical, digitalSignature, keyEncipherment
nsCertType           = client
nsComment            = "Admin Client Certificate"
subjectKeyIdentifier = hash
----

Every certificate authority starts with a private key and root certificate. In this section,
you will create a self-signed certificate authority, and while that is all you need for this tutorial,
this is something you should not consider in a real-world production environment.

Generate the CA configuration file, certificate, and private key:

[,bash]
----
openssl genrsa -out ca.key 4096
openssl req -x509 -new -sha512 -noenc \
    -key ca.key -days 3653 \
    -config ca.conf \
    -out ca.crt
----

You should now have `ca.crt` and `ca.key` in your directory.
You can view details of the `.crt` key by running: `openssl x509 -in ca.crt -text -noout | less`.

=== Create client/server certificates

In this section, you will generate client and server certificates for each Kubernetes
component and a client certificate for the Kubernetes admin user.

Generate the certificates and private keys:

.gen_keys.sh
[,bash]
----
#!/bin/bash

certs=(
  "admin" "mawenzi-02" "mawenzi-03"
  "kube-proxy" "kube-scheduler"
  "kube-controller-manager"
  "kube-api-server"
  "service-accounts"
)

for i in ${certs[*]}; do
  openssl genrsa -out "${i}.key" 4096

  openssl req -new -key "${i}.key" -sha256 \
    -config "ca.conf" -section ${i} \
    -out "${i}.csr"

  openssl x509 -req -days 3653 -in "${i}.csr" \
    -copy_extensions copyall \
    -sha256 -CA "ca.crt" \
    -CAkey "ca.key" \
    -CAcreateserial \
    -out "${i}.crt"
done
----

.Example
[,console]
----
[root@mawenzi-01 kubernetes]# ./gen_keys.sh
Certificate request self-signature ok
subject=CN=admin, O=system:masters
Certificate request self-signature ok
subject=CN=system:node:mawenzi-02, O=system:nodes, C=US, ST=Colorado, L=Denver
Certificate request self-signature ok
subject=CN=system:node:mawenzi-03, O=system:nodes, C=US, ST=Colorado, L=Denver
Certificate request self-signature ok
subject=CN=system:kube-proxy, O=system:node-proxier, C=US, ST=Colorado, L=Denver
Certificate request self-signature ok
subject=CN=system:kube-scheduler, O=system:system:kube-scheduler, C=US, ST=Colorado, L=Denver
Certificate request self-signature ok
subject=CN=system:kube-controller-manager, O=system:kube-controller-manager, C=US, ST=Colorado, L=Denver
Certificate request self-signature ok
subject=CN=kubernetes, C=US, ST=Colorado, L=Denver
Certificate request self-signature ok
subject=CN=service-accounts
----

The above command results will generate a private key, certificate request, and signed SSL certificate for each Kubernetes component.
You can list the generated files with the following command: `ls -1 *.crt *.key *.csr`

.Example
[,console]
----
admin.crt
admin.csr
admin.key
ca.crt
ca.key
kube-api-server.crt
kube-api-server.csr
kube-api-server.key
kube-controller-manager.crt
kube-controller-manager.csr
kube-controller-manager.key
kube-proxy.crt
kube-proxy.csr
kube-proxy.key
kube-scheduler.crt
kube-scheduler.csr
kube-scheduler.key
mawenzi-02.crt
mawenzi-02.csr
mawenzi-02.key
mawenzi-03.crt
mawenzi-03.csr
mawenzi-03.key
service-accounts.crt
service-accounts.csr
service-accounts.key
----

=== Distribute the keys

Use the following script to distribute the keys and certificates to the worker nodes:

[,bash]
----
#!/bin/bash

worker_nodes=("mawenzi-02" "mawenzi-03")

for host in "${worker_nodes[@]}"; do
  ssh root@$host mkdir /var/lib/kubelet/
  scp ca.crt root@$host:/var/lib/kubelet/

  scp $host.crt \
    root@$host:/var/lib/kubelet/kubelet.crt

  scp $host.key \
    root@$host:/var/lib/kubelet/kubelet.key
done
----

=== Generate Kubernetes config files for authentication

https://docs.rockylinux.org/labs/kubernetes-the-hard-way/lab5-kubernetes-configuration-files/#the-kubelet-kubernetes-configuration-file

Now we'll generate kubeconfig files for the `kubelet` and the `admin` user.

When generating kubeconfig files for Kubelets you must match the client certificate to the Kubelet's node name.
This will ensure Kubelets are properly authorized by the https://kubernetes.io/docs/reference/access-authn-authz/node/[Kubernetes Note Authorizer].

We'll use the following script, `gen_kubeconfigs.sh`, to generate the kubeconfig files for the node kubelets,
kube-proxy, kube-controller-manager, kube-scheduler, and admin node.

.gen_kubeconfigs.sh
[,bash]
----
#!/bin/bash

cluster_name="mawenzi"
worker_nodes=("mawenzi-02" "mawenzi-03")
master_node="mawenzi-01"
services=("kube-proxy" "kube-controller-manager" "kube-scheduler")

# Worker node kubelet kubeconfig files
for host in "${worker_nodes[@]}"; do
  echo "Generating kubeconfig files for worker '$host' kubelet"
  kubectl config set-cluster $cluster_name \
    --certificate-authority=ca.crt \
    --embed-certs=true \
    --server=https://$master_node:6443 \
    --kubeconfig=${host}.kubeconfig

  kubectl config set-credentials system:node:${host} \
    --client-certificate=${host}.crt \
    --client-key=${host}.key \
    --embed-certs=true \
    --kubeconfig=${host}.kubeconfig

  kubectl config set-context default \
    --cluster=kubernetes-the-hard-way \
    --user=system:node:${host} \
    --kubeconfig=${host}.kubeconfig

  kubectl config use-context default \
    --kubeconfig=${host}.kubeconfig
done

# kube-proxy, kube-controller-manager, kube-scheduler
for service in "${services[@]}"; do
  kubectl config set-cluster $cluster_name \
    --certificate-authority=ca.crt \
    --embed-certs=true \
    --server=https://$master:6443 \
    --kubeconfig=$service.kubeconfig

  kubectl config set-credentials system:$service \
    --client-certificate=$service.crt \
    --client-key=$service.key \
    --embed-certs=true \
    --kubeconfig=$service.kubeconfig

  kubectl config set-context default \
    --cluster=$cluster_name \
    --user=system:$service \
    --kubeconfig=$service.kubeconfig

  kubectl config use-context default \
    --kubeconfig=$service.kubeconfig
done

# admin
kubectl config set-cluster $cluster_name \
    --certificate-authority=ca.crt \
    --embed-certs=true \
    --server=https://127.0.0.1:6443 \
    --kubeconfig=admin.kubeconfig

kubectl config set-credentials admin \
    --client-certificate=admin.crt \
    --client-key=admin.key \
    --embed-certs=true \
    --kubeconfig=admin.kubeconfig

kubectl config set-context default \
    --cluster=kubernetes-the-hard-way \
    --user=admin \
    --kubeconfig=admin.kubeconfig

kubectl config use-context default \
    --kubeconfig=admin.kubeconfig
done
----

Running this:

[,console]
----
[root@mawenzi-01 kubernetes]# ./gen_kubeconfigs.sh
Generating kubeconfig files for worker 'mawenzi-02' kubelet
Cluster "mawenzi" set.
User "system:node:mawenzi-02" set.
Context "default" modified.
Switched to context "default".
Generating kubeconfig files for worker 'mawenzi-03' kubelet
Cluster "mawenzi" set.
User "system:node:mawenzi-03" set.
Context "default" modified.
Switched to context "default".
Cluster "mawenzi" set.
User "system:kube-proxy" set.
Context "default" modified.
Switched to context "default".
Cluster "mawenzi" set.
User "system:kube-controller-manager" set.
Context "default" created.
Switched to context "default".
Cluster "mawenzi" set.
User "system:kube-scheduler" set.
Context "default" created.
Switched to context "default".
Cluster "mawenzi" set.
User "admin" set.
Context "default" created.
Switched to context "default".
----

And, we get:

* `admin.kubeconfig`
* `kube-controller-manager.kubeconfig`
* `kube-proxy.kubeconfig`
* `kube-scheduler.kubeconfig`
* `mawenzi-02.kubeconfig`
* `mawenzi-03.kubeconfig`

=== Generate encryption configuration and key

https://docs.rockylinux.org/labs/kubernetes-the-hard-way/lab6-data-encryption-keys/#lab-6-generating-the-data-encryption-configuration-and-key

We'll generate an encryption key and an encryption configuration suitable for encrypting
 https://kubernetes.io/docs/concepts/configuration/secret/[Kubernetes Secrets].

Generate a random encryption key, using `/dev/urandom` and `base64`:

[,bash]
----
export ENCRYPTION_KEY=$(head -c 32 /dev/urandom | base64)
----

.Example:
[,console]
----
[root@mawenzi-01 kubernetes]# echo $ENCRYPTION_KEY
wMCVvvm23ffr.............wx7naVcfsutjvED4Dg=
----

Create the following encryption config YAML file:

.encryption-config-template.yaml
[,yaml]
----
kind: EncryptionConfig
apiVersion: v1
resources:
  - resources:
      - secrets
    providers:
      - aescbc:
          keys:
            - name: key1
              secret: ${ENCRYPTION_KEY}
      - identity: {}
----

Then, substitute in the `$ENCRYPTION_KEY` variable:

[,bash]
----
envsubst < encryption-config-template.yaml > encryption-config.yaml
----

(it should look like this now)

.encryption-config.yaml
[,yaml]
----
kind: EncryptionConfig
apiVersion: v1
resources:
  - resources:
      - secrets
    providers:
      - aescbc:
          keys:
            - name: key1
              secret: wMCVvvm23ffr.............wx7naVcfsutjvED4Dg=
      - identity: {}
----




Check to make sure required ports are open: https://kubernetes.io/docs/reference/networking/ports-and-protocols/[Required Ports and Protocols]

.Example: Required port 6443 is not open
[,console]
----
[root@mawenzi-01 ~]# nc 127.0.0.1 6443 -zv -w 2
Ncat: Version 7.92 ( https://nmap.org/ncat )
Ncat: Connection refused.
----
<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>GPUDirect Storage (GDS) :: Caleb Carlson | Docs Site</title>
    <link rel="canonical" href="https://inf0rmatiker.github.io/docs-site/1/learning/gpus/gds.html">
    <meta name="generator" content="Antora 3.1.4">
    <link rel="stylesheet" href="../../../../_/css/site.css">
  </head>
  <body class="article">
<header class="header">
  <nav class="navbar">
    <div class="navbar-brand">
      <a class="navbar-item" href="https://inf0rmatiker.github.io">Caleb Carlson | Docs Site</a>
      <button class="navbar-burger" aria-controls="topbar-nav" aria-expanded="false" aria-label="Toggle main menu">
        <span></span>
        <span></span>
        <span></span>
      </button>
    </div>
    <div id="topbar-nav" class="navbar-menu">
      <div class="navbar-end">
        <a class="navbar-item" href="https://inf0rmatiker.github.io/">Home</a>
      </div>
    </div>
  </nav>
</header>
<div class="body">
<div class="nav-container" data-component="docs-site" data-version="1">
  <aside class="nav">
    <div class="panels">
<div class="nav-panel-menu is-active" data-panel="menu">
  <nav class="nav-menu">
    <button class="nav-menu-toggle" aria-label="Toggle expand/collapse all" style="display: none"></button>
    <h3 class="title"><a href="../../index.html">Documentation</a></h3>
<ul class="nav-list">
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="../../index.html">Overview</a>
  </li>
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <span class="nav-text">Projects</span>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <span class="nav-text">VU Meter</span>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../../projects/vu-meter/vu-meter.html">VU Meter</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <span class="nav-text">PC Exhaust</span>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../../projects/pc-exhaust/pc-exhaust.html">PC Exhaust</a>
  </li>
</ul>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <span class="nav-text">Learning</span>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <span class="nav-text">Kubernetes</span>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../kubernetes/crds.html">CRDs</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../kubernetes/k8s-api-resources.html">Kubernetes Resources</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../kubernetes/k8s-install.html">Kubernetes Install</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../kubernetes/kubectl.html">kubectl</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <span class="nav-text">Lustre</span>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../lustre/benchmarks.html">Benchmarks</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../lustre/compiling-lustre.html">Compiling Lustre</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../lustre/development.html">Development</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../lustre/lustre-client.html">Lustre Client</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../lustre/lustre-server.html">Lustre Server</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../lustre/lustre-networking.html">Lustre Networking</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <span class="nav-text">Linux</span>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <button class="nav-item-toggle"></button>
    <span class="nav-text">Installs</span>
<ul class="nav-list">
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="../linux/installs/rocky-install.html">Rocky Linux Install</a>
  </li>
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="../linux/installs/opensuse-install.html">OpenSUSE Linux Install</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../linux/isos.html">ISOs</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../linux/rpms.html">RPMs</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../linux/tmux.html">Tmux</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../linux/user-management.html">User Management</a>
  </li>
  <li class="nav-item" data-depth="3">
    <button class="nav-item-toggle"></button>
    <span class="nav-text">Networking</span>
<ul class="nav-list">
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="../linux/networking/linux-networking.html">Linux</a>
  </li>
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="../linux/networking/mpi.html">MPI</a>
  </li>
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="../linux/networking/proxies.html">Proxies</a>
  </li>
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="../linux/networking/rdma.html">RDMA Programming</a>
  </li>
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="../linux/networking/socket_programming.html">Socket Programming</a>
  </li>
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="../linux/networking/ssh.html">SSH</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="3">
    <button class="nav-item-toggle"></button>
    <span class="nav-text">Storage</span>
<ul class="nav-list">
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="../linux/storage/benchmarks.html">Benchmarks</a>
  </li>
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="../linux/storage/filesystems.html">Filesystems</a>
  </li>
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="../linux/storage/drives.html">Drives</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../linux/vms/virtual-machines.html">Virtual Machines</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <span class="nav-text">Docker</span>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../docker/multiarch-building.html">Multi-Architecture Builds</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../docker/nginx-webserver.html">Nginx Webserver</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../docker/registry-proxy.html">Registry Proxy</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../asciinema/asciinema.html">Asciinema</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../bmc-management/bmc-management.html">BMC Management</a>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <span class="nav-text">Version Control</span>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../version-control/git/git.html">Git</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../version-control/github/github.html">GitHub</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <span class="nav-text">Algorithms</span>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../algorithms/dynamic-programming.html">Dynamic Programming</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../algorithms/sliding-window.html">Sliding Window</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <span class="nav-text">Machine Learning</span>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../machine-learning/benchmarks.html">Benchmarks</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../machine-learning/determinedai.html">Determined AI</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <span class="nav-text">REST APIs</span>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../rest-apis/api-security.html">Secure Development</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <span class="nav-text">InfiniBand</span>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../infiniband/infiniband.html">InfiniBand</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../infiniband/monitoring.html">Fabric Monitoring</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <span class="nav-text">Languages</span>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <button class="nav-item-toggle"></button>
    <span class="nav-text">C</span>
<ul class="nav-list">
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="../languages/c/getopt.html">Getopt</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="3">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../languages/cpp/cpp.html">C++</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="../languages/cpp/arrays.html">Arrays</a>
  </li>
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="../languages/cpp/branch_control.html">Branch Control</a>
  </li>
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="../languages/cpp/classes.html">Classes</a>
  </li>
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="../languages/cpp/compiling.html">Compiling and Executing</a>
  </li>
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="../languages/cpp/development_environment.html">Development Environment</a>
  </li>
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="../languages/cpp/error_handling.html">Error Handling</a>
  </li>
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="../languages/cpp/functions.html">Functions</a>
  </li>
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="../languages/cpp/input_streams.html">Input Streams</a>
  </li>
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="../languages/cpp/macros.html">Macros</a>
  </li>
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="../languages/cpp/pointers.html">Pointers</a>
  </li>
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="../languages/cpp/references.html">References</a>
  </li>
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="../languages/cpp/structures.html">Stuctures</a>
  </li>
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="../languages/cpp/types.html">Types</a>
  </li>
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="../languages/cpp/vectors.html">Vectors</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../languages/go/go.html">Go</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../slurm/slurm.html">Slurm</a>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <span class="nav-text">GPUs</span>
<ul class="nav-list">
  <li class="nav-item is-current-page" data-depth="3">
    <a class="nav-link" href="gds.html">GPUDirect Storage</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="numa.html">NUMA</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../switch-management/switch-management.html">Switch Management</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../hpcm/hpcm.html">HPCM</a>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <span class="nav-text">todo</span>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../todo/todo.html">todo</a>
  </li>
</ul>
  </li>
</ul>
  </li>
</ul>
  </li>
</ul>
  </nav>
</div>
<div class="nav-panel-explore" data-panel="explore">
  <div class="context">
    <span class="title">Documentation</span>
    <span class="version">1</span>
  </div>
  <ul class="components">
    <li class="component is-current">
      <div class="title"><a href="../../index.html">Documentation</a></div>
      <ul class="versions">
        <li class="version is-current is-latest">
          <a href="../../index.html">1</a>
        </li>
      </ul>
    </li>
  </ul>
</div>
    </div>
  </aside>
</div>
<main class="article">
<div class="toolbar" role="navigation">
<button class="nav-toggle"></button>
  <a href="../../index.html" class="home-link"></a>
<nav class="breadcrumbs" aria-label="breadcrumbs">
  <ul>
    <li><a href="../../index.html">Documentation</a></li>
    <li>Learning</li>
    <li>GPUs</li>
    <li><a href="gds.html">GPUDirect Storage</a></li>
  </ul>
</nav>
</div>
  <div class="content">
<aside class="toc sidebar" data-title="Contents" data-levels="2">
  <div class="toc-menu"></div>
</aside>
<article class="doc">
<h1 class="page">GPUDirect Storage (GDS)</h1>
<div id="preamble">
<div class="sectionbody">
<div class="paragraph">
<p>This document provides notes for installing and using <a href="https://docs.nvidia.com/gpudirect-storage/index.html">Nvidia&#8217;s GPUDirect Storage</a>.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_nvidia_cuda_installation_with_gds"><a class="anchor" href="#_nvidia_cuda_installation_with_gds"></a>Nvidia / CUDA Installation with GDS</h2>
<div class="sectionbody">
<div class="paragraph">
<p>To use NVIDIA CUDA on your system, you will need the following installed:
CUDA Toolkit (available at <a href="https://developer.nvidia.com/cuda-downloads" class="bare">https://developer.nvidia.com/cuda-downloads</a>)</p>
</div>
<div class="paragraph">
<p><a href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#install-prereqs">Install Prerequisites</a></p>
</div>
<div class="ulist">
<ul>
<li>
<p><a href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html">CUDA Installation</a></p>
</li>
<li>
<p><a href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#gds-installing">GDS Installation</a></p>
</li>
<li>
<p><a href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#install-gpudirect-storage">GDS Installation via CUDA</a></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>It&#8217;s easiest to just install the CUDA toolkit and drivers, along with <code>nvidia-fs</code> via <code>apt</code> which includes GDS.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
If you&#8217;re using InfiniBand, you need to have MOFED installed prior to installing GDS.
</td>
</tr>
</table>
</div>
<div class="sect2">
<h3 id="_ubuntu_22_04"><a class="anchor" href="#_ubuntu_22_04"></a>Ubuntu 22.04</h3>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">#!/bin/bash

apt-get install \
	cuda-drivers-535="535.104.05-1" \
	cuda-drivers-fabricmanager-535="535.104.05-1" \
	cuda-drivers-fabricmanager="535.104.05-1" \
	libnvidia-cfg1-535="535.104.05-0ubuntu1" \
	libnvidia-common-535="535.104.05-0ubuntu1" \
	libnvidia-compute-535="535.104.05-0ubuntu1" \
	libnvidia-container-tools="1.14.1-1" \
	libnvidia-container1="1.14.1-1" \
	libnvidia-decode-535="535.104.05-0ubuntu1" \
	libnvidia-encode-535="535.104.05-0ubuntu1" \
	libnvidia-extra-535="535.104.05-0ubuntu1" \
	libnvidia-fbc1-535="535.104.05-0ubuntu1" \
	libnvidia-gl-535="535.104.05-0ubuntu1" \
	nvidia-compute-utils-535="535.104.05-0ubuntu1" \
	nvidia-container-toolkit-base="1.14.1-1" \
	nvidia-container-toolkit="1.14.1-1" \
	nvidia-dkms-535="535.104.05-0ubuntu1" \
	nvidia-docker2="2.13.0-1" \
	nvidia-driver-535="535.104.05-0ubuntu1" \
	nvidia-fabricmanager-535="535.104.05-1" \
	nvidia-fs-dkms="2.17.5-1" \
	nvidia-fs="2.17.5-1" \
	nvidia-gds-12-2="12.2.2-1" \
	nvidia-gds="12.2.2-1" \
	nvidia-kernel-common-535="535.104.05-0ubuntu1" \
	nvidia-kernel-source-535="535.104.05-0ubuntu1" \
	nvidia-modprobe="535.104.05-0ubuntu1" \
	nvidia-prime="0.8.17.1" \
	nvidia-settings="535.104.05-0ubuntu1" \
	nvidia-utils-535="535.104.05-0ubuntu1" \
	xserver-xorg-video-nvidia-535="535.104.05-0ubuntu1"</code></pre>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_installing_open_source_nvidia_drivers"><a class="anchor" href="#_installing_open_source_nvidia_drivers"></a>Installing Open-Source Nvidia Drivers</h3>
<div class="paragraph">
<p>For Ubuntu 22.04, follow <a href="https://developer.nvidia.com/cuda-downloads?target_os=Linux&amp;target_arch=x86_64&amp;Distribution=Ubuntu&amp;target_version=22.04&amp;target_type=deb_local">Nvidia CUDA Toolkit Installation Guide</a>.</p>
</div>
<div class="paragraph">
<p>Base installer installation instructions for CUDA 12.3:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-console hljs" data-lang="console">wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64/cuda-ubuntu2204.pin
sudo mv cuda-ubuntu2204.pin /etc/apt/preferences.d/cuda-repository-pin-600
wget https://developer.download.nvidia.com/compute/cuda/12.3.1/local_installers/cuda-repo-ubuntu2204-12-3-local_12.3.1-545.23.08-1_amd64.deb
sudo dpkg -i cuda-repo-ubuntu2204-12-3-local_12.3.1-545.23.08-1_amd64.deb
sudo cp /var/cuda-repo-ubuntu2204-12-3-local/cuda-*-keyring.gpg /usr/share/keyrings/
sudo apt-get update
sudo apt-get -y install cuda-toolkit-12-3</code></pre>
</div>
</div>
<div class="paragraph">
<p><a href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/#meta-packages">Additional installation options</a></p>
</div>
<div class="paragraph">
<p>NVIDIA driver installation instructions:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-console hljs" data-lang="console">sudo apt-get install -y nvidia-kernel-open-545
sudo apt-get install -y cuda-drivers-545</code></pre>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_rhel_8_6"><a class="anchor" href="#_rhel_8_6"></a>RHEL 8.6</h3>
<div class="ulist">
<ul>
<li>
<p><a href="https://docs.nvidia.com/dgx/dgx-rhel8-install-guide/upgrading-dgx-sw.html#installing-gpudirect-storage-support">Installing GDS for RHEL 8</a></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>You&#8217;ll need to have the appropriate CUDA toolkit, appropriate Nvidia drivers, and CUDA drivers installed as a prerequisite.</p>
</div>
<div class="paragraph">
<p>Below is a list of all the Nvidia-related bits installed on a working GDS-enabled Rocky Linux 8.6 system:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-console hljs" data-lang="console">[carlsonc@aixl675dn04 ~]$ dnf list --installed "*nvidia*" "*cuda*" "*gds*"
Installed Packages
cuda-crt-12-3.x86_64                                                             12.3.103-1                                                    @cuda-rhel8-x86_64
cuda-driver-devel-12-1.x86_64                                                    12.1.105-1                                                    @cuda-rhel8-12-1-local
cuda-driver-devel-12-3.x86_64                                                    12.3.101-1                                                    @cuda-rhel8-x86_64
cuda-drivers.x86_64                                                              545.23.08-1                                                   @cuda-rhel8-x86_64
cuda-nvcc-12-3.x86_64                                                            12.3.103-1                                                    @cuda-rhel8-x86_64
cuda-nvvm-12-3.x86_64                                                            12.3.103-1                                                    @cuda-rhel8-x86_64
cuda-repo-rhel8-12-1-local.x86_64                                                12.1.1_530.30.02-1                                            @System
cuda-toolkit-12-3-config-common.noarch                                           12.3.101-1                                                    @cuda-rhel8-x86_64
cuda-toolkit-12-config-common.noarch                                             12.1.105-1                                                    @cuda-rhel8-12-1-local
cuda-toolkit-config-common.noarch                                                12.1.105-1                                                    @cuda-rhel8-12-1-local
dnf-plugin-nvidia.noarch                                                         2.0-1.el8                                                     @nvidia_cuda-rhel8-11.8.0_13
gds-partners.x86_64                                                              1.8.0-1                                                       @System
gds-tools-12-3.x86_64                                                            1.8.1.2-1                                                     @cuda-rhel8-x86_64
kmod-nvidia-latest-dkms.x86_64                                                   3:545.23.08-1.el8                                             @cuda-rhel8-x86_64
libnvidia-container-tools.x86_64                                                 1.14.3-1                                                      @cuda-rhel8-x86_64
libnvidia-container1.x86_64                                                      1.14.3-1                                                      @cuda-rhel8-x86_64
nvidia-container-toolkit.x86_64                                                  1.14.3-1                                                      @cuda-rhel8-x86_64
nvidia-container-toolkit-base.x86_64                                             1.14.3-1                                                      @cuda-rhel8-x86_64
nvidia-driver.x86_64                                                             3:545.23.08-1.el8                                             @cuda-rhel8-x86_64
nvidia-driver-NVML.x86_64                                                        3:545.23.08-1.el8                                             @cuda-rhel8-x86_64
nvidia-driver-NvFBCOpenGL.x86_64                                                 3:545.23.08-1.el8                                             @cuda-rhel8-x86_64
nvidia-driver-cuda.x86_64                                                        3:545.23.08-1.el8                                             @cuda-rhel8-x86_64
nvidia-driver-cuda-libs.x86_64                                                   3:545.23.08-1.el8                                             @cuda-rhel8-x86_64
nvidia-driver-devel.x86_64                                                       3:545.23.08-1.el8                                             @cuda-rhel8-x86_64
nvidia-driver-libs.x86_64                                                        3:545.23.08-1.el8                                             @cuda-rhel8-x86_64
nvidia-fabric-manager.x86_64                                                     545.23.08-1                                                   @cuda-rhel8-x86_64
nvidia-fs.x86_64                                                                 2.18.3-1                                                      @cuda-rhel8-x86_64
nvidia-fs-dkms.x86_64                                                            2.18.3-1                                                      @cuda-rhel8-x86_64
nvidia-gds.x86_64                                                                12.3.1-1                                                      @cuda-rhel8-x86_64
nvidia-gds-12-3.x86_64                                                           12.3.1-1                                                      @cuda-rhel8-x86_64
nvidia-kmod-common.noarch                                                        3:545.23.08-1.el8                                             @cuda-rhel8-x86_64
nvidia-libXNVCtrl.x86_64                                                         3:545.23.08-1.el8                                             @cuda-rhel8-x86_64
nvidia-libXNVCtrl-devel.x86_64                                                   3:545.23.08-1.el8                                             @cuda-rhel8-x86_64
nvidia-modprobe.x86_64                                                           3:545.23.08-1.el8                                             @cuda-rhel8-x86_64
nvidia-persistenced.x86_64                                                       3:545.23.08-1.el8                                             @cuda-rhel8-x86_64
nvidia-settings.x86_64                                                           3:545.23.08-1.el8                                             @cuda-rhel8-x86_64
nvidia-xconfig.x86_64                                                            3:545.23.08-1.el8                                             @cuda-rhel8-x86_64
nvidia_peer_memory.x86_64                                                        1.1-0                                                         @@System</code></pre>
</div>
</div>
<div class="paragraph">
<p>NOTE:
This might be <em>more</em> than the minimum you need to get GDS up and running, but we know for certain that things work with all this installed.</p>
</div>
<div class="paragraph">
<p>This is what&#8217;s in the <code>cuda-rhel8-x86_64</code> repofile:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-console hljs" data-lang="console">[carlsonc@aixl675dn04 ~]$ cat /etc/yum.repos.d/cuda-rhel8.repo
[cuda-rhel8-x86_64]
name=cuda-rhel8-x86_64
baseurl=https://developer.download.nvidia.com/compute/cuda/repos/rhel8/x86_64
enabled=1
gpgcheck=1
gpgkey=https://developer.download.nvidia.com/compute/cuda/repos/rhel8/x86_64/D42D0685.pub</code></pre>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_verifying_installation"><a class="anchor" href="#_verifying_installation"></a>Verifying Installation</h3>
<div class="paragraph">
<p>Verify your GDS installation works on your platform with Lustre by running <code>/usr/local/cuda-&lt;version&gt;/gds/tools/gdscheck -p</code>:</p>
</div>
<div class="listingblock">
<div class="title">Example</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-console hljs" data-lang="console">ccarlson@o186i225:~$ /usr/local/cuda-12.4/gds/tools/gdscheck -p
 GDS release version: 1.9.0.20
 nvidia_fs version:  2.19 libcufile version: 2.12
 Platform: x86_64
 ============
 ENVIRONMENT:
 ============
 CUFILE_ENV_PATH_JSON : /home/ccarlson/gds/cufile.json
 =====================
 DRIVER CONFIGURATION:
 =====================
 NVMe               : Unsupported
 NVMeOF             : Unsupported
 SCSI               : Unsupported
 ScaleFlux CSD      : Unsupported
 NVMesh             : Unsupported
 DDN EXAScaler      : Supported
 IBM Spectrum Scale : Unsupported
 NFS                : Supported
 BeeGFS             : Unsupported
 WekaFS             : Supported
 Userspace RDMA     : Supported
 --Mellanox PeerDirect : Enabled
 --rdma library        : Loaded (libcufile_rdma.so)
 --rdma devices        : Configured
 --rdma_device_status  : Up: 4 Down: 0
 =====================
 CUFILE CONFIGURATION:
 =====================
 properties.use_compat_mode : false
 properties.force_compat_mode : false
 properties.gds_rdma_write_support : true
 properties.use_poll_mode : false
 properties.poll_mode_max_size_kb : 4096
 properties.max_batch_io_size : 128
 properties.max_batch_io_timeout_msecs : 5
 properties.max_direct_io_size_kb : 16384
 properties.max_device_cache_size_kb : 131072
 properties.max_device_pinned_mem_size_kb : 33554432
 properties.posix_pool_slab_size_kb : 4 1024 16384
 properties.posix_pool_slab_count : 128 64 32
 properties.rdma_peer_affinity_policy : RoundRobinMaxMin
 properties.rdma_dynamic_routing : 1
 properties.rdma_dynamic_routing_order : GPU_MEM_NVLINKS GPU_MEM SYS_MEM P2P
 fs.generic.posix_unaligned_writes : false
 fs.lustre.posix_gds_min_kb: 0
 fs.lustre.mount_table :
 /e1000  dev_id 1199770272 : 172.22.186.225 172.22.194.225 172.22.202.225 172.22.210.225
 fs.beegfs.posix_gds_min_kb: 0
 fs.weka.rdma_write_support: false
 fs.gpfs.gds_write_support: false
 profile.nvtx : false
 profile.cufile_stats : 0
 miscellaneous.api_check_aggressive : false
 execution.max_io_threads : 4
 execution.max_io_queue_depth : 128
 execution.parallel_io : true
 execution.min_io_threshold_size_kb : 8192
 execution.max_request_parallelism : 4
 properties.force_odirect_mode : false
 properties.prefer_iouring : false
 =========
 GPU INFO:
 =========
 GPU index 0 NVIDIA A100-SXM4-80GB bar:1 bar size (MiB):131072 supports GDS, IOMMU State: Disabled
 GPU index 1 NVIDIA A100-SXM4-80GB bar:1 bar size (MiB):131072 supports GDS, IOMMU State: Disabled
 GPU index 2 NVIDIA A100-SXM4-80GB bar:1 bar size (MiB):131072 supports GDS, IOMMU State: Disabled
 GPU index 3 NVIDIA A100-SXM4-80GB bar:1 bar size (MiB):131072 supports GDS, IOMMU State: Disabled
 GPU index 4 NVIDIA A100-SXM4-80GB bar:1 bar size (MiB):131072 supports GDS, IOMMU State: Disabled
 GPU index 5 NVIDIA A100-SXM4-80GB bar:1 bar size (MiB):131072 supports GDS, IOMMU State: Disabled
 GPU index 6 NVIDIA A100-SXM4-80GB bar:1 bar size (MiB):131072 supports GDS, IOMMU State: Disabled
 GPU index 7 NVIDIA A100-SXM4-80GB bar:1 bar size (MiB):131072 supports GDS, IOMMU State: Disabled
 ==============
 PLATFORM INFO:
 ==============
 IOMMU: disabled
 Nvidia Driver Info Status: Supported(Nvidia Open Driver Installed)
 Cuda Driver Version Installed:  12040
 Platform: ProLiant XL675d Gen10 Plus, Arch: x86_64(Linux 5.15.0-100-generic)
 Platform verification succeeded</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Note the <code>DDN EXAScaler      : Supported</code>: this indicates Lustre is supported.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>You can check the GDS filesystem support by running <code>/usr/local/cuda-&lt;version&gt;/gds/tools/gdscheck.py -V</code>:</p>
</div>
<div class="listingblock">
<div class="title">Example</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-console hljs" data-lang="console">FILESYSTEM VERSION CHECK:
Pre-requisite:
nvidia_peermem is loaded as required
nvme module is loaded
nvme module is not patched or not loaded
nvme-rdma module is not loaded
ScaleFlux module is not loaded
NVMesh module is not loaded
Lustre module is loaded
Lustre module is correctly patched
BeeGFS module is loaded
BeeGFS module is not patched or not loaded
GPFS module is not loaded
rpcrdma module is loaded
rpcrdma module is correctly patched
Lustre:
current version: 2.15.4 (Supported)
min version supported: 2.12.3_ddn28
ofed_info:
current version: MLNX_OFED_LINUX-24.01-0.3.3.1: (Supported)
min version supported: MLNX_OFED_LINUX-4.6-1.0.1.1</code></pre>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_removing_cuda_toolkit_and_drivers"><a class="anchor" href="#_removing_cuda_toolkit_and_drivers"></a>Removing CUDA Toolkit and Drivers</h3>
<div class="paragraph">
<p><a href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#removing-cuda-toolkit-and-driver">Nvidia - Removing CUDA Toolkit and Drivers</a></p>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_lustre_filesystem_benchmarks"><a class="anchor" href="#_lustre_filesystem_benchmarks"></a>Lustre Filesystem Benchmarks</h2>
<div class="sectionbody">
<div class="paragraph">
<p>We&#8217;ll be benchmarking GDS against a Lustre filesystem over RDMA.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
Make sure to have <a href="../lustre/lustre-client.html#_lustre_client_tunings" class="xref page">tuned your Lustre client</a> before starting experiments, otherwise performance will be impacted.
</td>
</tr>
</table>
</div>
<div class="sect2">
<h3 id="_configuration"><a class="anchor" href="#_configuration"></a>Configuration</h3>
<div class="sect3">
<h4 id="_lustre_filesystem"><a class="anchor" href="#_lustre_filesystem"></a>Lustre Filesystem</h4>
<div class="paragraph">
<p>The Lustre filesystem is being served from 4 InfiniBand HDR High-speed Channel Adapters (HCAs):</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-console hljs" data-lang="console">ccarlson@o186i225:~$ mount -t lustre
172.22.184.42@o2ib:172.22.184.43@o2ib:/seagate on /cstor type lustre (rw,nochecksum,flock,nouser_xattr,lruresize,lazystatfs,nouser_fid2path,verbose,noencrypt)
172.22.187.183@o2ib,172.22.187.184@o2ib:172.22.187.185@o2ib,172.22.187.186@o2ib:/cstor1 on /e1000 type lustre (rw,nochecksum,noflock,nouser_xattr,lruresize,lazystatfs,nouser_fid2path,verbose,encrypt)</code></pre>
</div>
</div>
<div class="paragraph">
<p>The filesystem server layout is as follows:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>There are two MDTs, both flash-based</p>
</li>
<li>
<p>There are two OSTs which are flash based, the remaining four are disk-based.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-console hljs" data-lang="console">ccarlson@o186i225:~$ lfs df /e1000
UUID                   1K-blocks        Used   Available Use% Mounted on
cstor1-MDT0000_UUID  12680735564     4607868 12505326916   1% /e1000[MDT:0]
cstor1-MDT0001_UUID  12680735564      424632 12509510152   1% /e1000[MDT:1]
cstor1-OST0000_UUID  65092016776 43759881420 20675704416  68% /e1000[OST:0]
cstor1-OST0001_UUID  65092016776 44857958320 19577627516  70% /e1000[OST:1]
cstor1-OST0002_UUID  624268859304 23013721776 594959810400   4% /e1000[OST:2]
cstor1-OST0003_UUID  624268859304 23178814712 594794717464   4% /e1000[OST:3]
cstor1-OST0004_UUID  624268859304 22864999736 595108532440   4% /e1000[OST:4]
cstor1-OST0005_UUID  624268859304 23018661112 594954871064   4% /e1000[OST:5]
cstor1-OST0006_UUID  624268859304 24916151264 593057380912   5% /e1000[OST:6]
cstor1-OST0007_UUID  624268859304 25205560176 592767972000   5% /e1000[OST:7]
cstor1-OST0008_UUID  624268859304 24378180764 593595351412   4% /e1000[OST:8]
cstor1-OST0009_UUID  624268859304 24641586624 593331945552   4% /e1000[OST:9]
cstor1-OST000a_UUID  32551608660  9894559412 22328769268  31% /e1000[OST:10]
cstor1-OST000b_UUID  32551608660  9907463744 22315864936  31% /e1000[OST:11]

filesystem_summary:  5189438125304 299637539060 4837468547380   6% /e1000</code></pre>
</div>
</div>
<div class="paragraph">
<p>We&#8217;ve got a directory, <code>/e1000/ccarlson</code>, which has its stripe set to the flash pool only:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-console hljs" data-lang="console">ccarlson@o186i225:~$ lfs getstripe /e1000/ccarlson
/e1000/ccarlson
stripe_count:  1 stripe_size:   1048576 pattern:       0 stripe_offset: -1

/e1000/ccarlson/fio
stripe_count:  1 stripe_size:   1048576 pattern:       raid0 stripe_offset: -1 pool:          flash

/e1000/ccarlson/ior
stripe_count:  1 stripe_size:   1048576 pattern:       raid0 stripe_offset: -1 pool:          flash

/e1000/ccarlson/gds
stripe_count:  1 stripe_size:   1048576 pattern:       raid0 stripe_offset: -1 pool:          flash</code></pre>
</div>
</div>
<div class="paragraph">
<p>You can set the stripe to flash on a directory using the following command:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">lfs setstripe -c 1 -p cstor1.flash /e1000/ccarlson/fio</code></pre>
</div>
</div>
<div class="paragraph">
<p>Where <code>cstor1</code> is the filesystem name and <code>/e1000/ccarlson/fio</code> is the directory.</p>
</div>
</div>
<div class="sect3">
<h4 id="_cufile_json"><a class="anchor" href="#_cufile_json"></a><code>cufile.json</code></h4>
<div class="paragraph">
<p>We&#8217;ve defined a custom <code>/home/hpcd/carlsonc/gdsio/cufile.json</code>, using the default <code>/etc/cufile.json</code> provided as the starting point,
and have populated it with the following parameters:</p>
</div>
<div class="listingblock">
<div class="title"><code>cufile.json</code></div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-json hljs" data-lang="json">{
  // NOTE : Application can override custom configuration via export CUFILE_ENV_PATH_JSON=&lt;filepath&gt;
  // e.g : export CUFILE_ENV_PATH_JSON="/home/&lt;xxx&gt;/cufile.json"

  "logging": {
    // log directory, if not enabled will create log file under current working directory
    "dir": "/home/ccarlson/gds/cufile_logs",
    // NOTICE|ERROR|WARN|INFO|DEBUG|TRACE (in decreasing order of severity)
    "level": "INFO"
  },

  "profile": {
    // nvtx profiling on/off
    "nvtx": false,
    // cufile stats level(0-3)
    "cufile_stats": 0
  },

  "execution" : {
    // max number of workitems in the queue;
    "max_io_queue_depth": 128,
    // max number of host threads per gpu to spawn for parallel IO
    "max_io_threads" : 4,
    // enable support for parallel IO
    "parallel_io" : true,
    // minimum IO threshold before splitting the IO
    "min_io_threshold_size_kb" : 8192,
    // maximum parallelism for a single request
    "max_request_parallelism" : 4
  },

  "properties": {
    // max IO chunk size (parameter should be multiples of 64K) used by cuFileRead/Write internally per IO request
    "max_direct_io_size_kb" : 16384,
    // device memory size (parameter should be 4K aligned) for reserving bounce buffers for the entire GPU
    "max_device_cache_size_kb" : 131072,
    // limit on maximum device memory size (parameter should be 4K aligned) that can be pinned for a given process
    "max_device_pinned_mem_size_kb" : 33554432,
    // true or false (true will enable asynchronous io submission to nvidia-fs driver)
    // Note : currently the overall IO will still be synchronous
    "use_poll_mode" : false,
    // maximum IO request size (parameter should be 4K aligned) within or equal to which library will use polling for IO completion
    "poll_mode_max_size_kb": 4096,
    // allow compat mode, this will enable use of cuFile posix read/writes
    "allow_compat_mode": false,
    // enable GDS write support for RDMA based storage
    "gds_rdma_write_support": true,
    // GDS batch size
    "io_batchsize": 128,
    // enable io priority w.r.t compute streams
    // valid options are "default", "low", "med", "high"
    "io_priority": "high",
    // client-side rdma addr list for user-space file-systems(e.g ["10.0.1.0", "10.0.2.0"])
    "rdma_dev_addr_list": [ "172.22.186.225", "172.22.194.225", "172.22.202.225", "172.22.210.225" ],
    // load balancing policy for RDMA memory registration(MR), (RoundRobin, RoundRobinMaxMin)
    // In RoundRobin, MRs will be distributed uniformly across NICS closest to a GPU
    // In RoundRobinMaxMin, MRs will be distributed across NICS closest to a GPU
    // with minimal sharing of NICS acros GPUS
    "rdma_load_balancing_policy": "RoundRobinMaxMin",
    //32-bit dc key value in hex
    //"rdma_dc_key": "0xffeeddcc",
    //To enable/disable different rdma OPs use the below bit map
    //Bit 0 - If set enables Local RDMA WRITE
    //Bit 1 - If set enables Remote RDMA WRITE
    //Bit 2 - If set enables Remote RDMA READ
    //Bit 3 - If set enables REMOTE RDMA Atomics
    //Bit 4 - If set enables Relaxed ordering.
    //"rdma_access_mask": "0x1f",
    // In platforms where IO transfer to a GPU will cause cross RootPort PCie transfers, enabling this feature
    // might help improve overall BW provided there exists a GPU(s) with Root Port common to that of the storage NIC(s).
    // If this feature is enabled, please provide the ip addresses used by the mount either in file-system specific
    // section for mount_table or in the rdma_dev_addr_list property in properties section
    "rdma_dynamic_routing": true,
    // The order describes the sequence in which a policy is selected for dynamic routing for cross Root Port transfers
    // If the first policy is not applicable, it will fallback to the next and so on.
    // policy GPU_MEM_NVLINKS: use GPU memory with NVLink to transfer data between GPUs
    // policy GPU_MEM: use GPU memory with PCIe to transfer data between GPUs
    // policy SYS_MEM: use system memory with PCIe to transfer data to GPU
    // policy P2P: use P2P PCIe to transfer across between NIC and GPU
    "rdma_dynamic_routing_order": [ "GPU_MEM_NVLINKS", "GPU_MEM", "SYS_MEM", "P2P" ]
  },

  "fs": {
    "generic": {
      // for unaligned writes, setting it to true will, cuFileWrite use posix write internally instead of regular GDS write
      "posix_unaligned_writes" : false
    },
    "beegfs" : {},
    "lustre": {
      // IO threshold for read/write (param should be 4K aligned)) equal to or below which cuFile will use posix read/write
      "posix_gds_min_kb" : 0,
      // To restrict the IO to selected IP list, when dynamic routing is enabled
      // if using a single lustre mount, provide the ip addresses here (use : sudo lnetctl net show)
      // if using multiple lustre mounts, provide ip addresses used by respective mount here
      "mount_table" : {
        "/e1000" : {
	  "rdma_dev_addr_list": ["172.22.186.225", "172.22.194.225", "172.22.202.225", "172.22.210.225"]
	}
      }
    },
    "nfs": {},
    "gpfs": {},
    "weka": {}
  },

  "denylist": {
    // specify list of vendor driver modules to deny for nvidia-fs (e.g. ["nvme" , "nvme_rdma"])
    "drivers":  [],

    // specify list of block devices to prevent IO using cuFile (e.g. [ "/dev/nvme0n1" ])
    "devices": [],

    // specify list of mount points to prevent IO using cuFile (e.g. ["/mnt/test"])
    "mounts": [],

    // specify list of file-systems to prevent IO using cuFile (e.g ["lustre", "wekafs"])
    "filesystems": []
  },

  "miscellaneous": {
    // enable only for enforcing strict checks at API level for debugging
    "api_check_aggressive": false
  }
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>Some things to note about the above <code>cufile.json</code>:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>We&#8217;ll be using <em>this</em> cuFile spec, overriding the default one, by exporting <code>CUFILE_ENV_PATH_JSON="/home/ccarlson/gds/cufile.json"</code>
before our <code>gdsio</code> execution.</p>
</li>
<li>
<p>I&#8217;ve turned up logging to <code>INFO</code> and am outputting logs to my directory <code>/home/ccarlson/gds/cufile_logs</code>.</p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_gdsio_jobfile"><a class="anchor" href="#_gdsio_jobfile"></a>GDSIO Jobfile</h4>
<div class="paragraph">
<p>Next up, we have our <code>write.gdsio</code> job file:</p>
</div>
<div class="listingblock">
<div class="title">write.gdsio</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">#
# sample config file gdsio.
# config file rules :
#   -provide a global section defined with [global]
#   -provide a job(s) must follow this signature [job-name-xxx]
#   -use newline to mark end of each section except last
#   -for comments, add # to the start of a line
#
[global]
name=gds-write
#0 - Storage-&gt;GPU (GDS)
#1 - Storage-&gt;CPU
#2 - Storage-&gt;CPU-&gt;GPU
#3 - Storage-&gt;CPU-&gt;GPU_ASYNC
#4 - Storage-&gt;PAGE_CACHE-&gt;CPU-&gt;GPU
#5 - Storage-&gt;GPU_ASYNC
#6 - Storage-&gt;GPU_BATCH
#7 - Storage-&gt;GPU_BATCH_STREAM
xfer_type=0
#IO type, rw=read, rw=write, rw=randread, rw=randwrite
rw=write
#block size, for variable block size can specify range e.g. bs=1M:4M:1M, (1M : start block size, 4M : end block size, 1M :steps in which size is varied)
bs=4M
#file-size
size=4G
#secs
runtime=60
#use 1 for enabling verification
do_verify=0
#skip cufile buffer registration, ignored in cpu mode
skip_bufregister=0
#set up NVlinks, recommended if p2p traffic is cross node
enable_nvlinks=1
#use random seed
random_seed=0
#fill request buffer with random data
fill_random=0
#refill io buffer after every write
refill_buffer=0
#use random offsets which are not page-aligned
unaligned_random=0
#file offset to start read/write from
start_offset=0
#alignment size for random IO
#alignment_size=64K


[job0]
#numa node
#numa_node=0
#gpu device index (check nvidia-smi)
gpu_dev_id=0
#For Xfer mode 6, num_threads will be used as batch_size
num_threads=$NUM_GDS_THREADS_PER_GPU
#enable either directory or filename or url
directory=/e1000/ccarlson/gds/o186i221/gpu0
#filename=/mnt/test0/gds-01
#rdma_url=sockfs://192.186.0.1:18515
#The following parameter can be used to specify per job start offset. If not defined global section's start offset would be used.
#start_offset=0
#The following parameter can be used to define the size of IO for this job. If not defined, the global size parameter would be used.
#For Xfer mode 6, this is per batch i.e. for 1MB size with a batch size of 4 would
#do 4 MB of I/O.
#size = 8M

[job1]
gpu_dev_id=1
num_threads=$NUM_GDS_THREADS_PER_GPU
directory=/e1000/ccarlson/gds/o186i221/gpu1

[job2]
gpu_dev_id=2
num_threads=$NUM_GDS_THREADS_PER_GPU
directory=/e1000/ccarlson/gds/o186i221/gpu2

[job3]
gpu_dev_id=3
num_threads=$NUM_GDS_THREADS_PER_GPU
directory=/e1000/ccarlson/gds/o186i221/gpu3

[job4]
gpu_dev_id=4
num_threads=$NUM_GDS_THREADS_PER_GPU
directory=/e1000/ccarlson/gds/o186i221/gpu4

[job5]
gpu_dev_id=5
num_threads=$NUM_GDS_THREADS_PER_GPU
directory=/e1000/ccarlson/gds/o186i221/gpu5

[job6]
gpu_dev_id=6
num_threads=$NUM_GDS_THREADS_PER_GPU
directory=/e1000/ccarlson/gds/o186i221/gpu6

[job7]
gpu_dev_id=7
num_threads=$NUM_GDS_THREADS_PER_GPU
directory=/e1000/ccarlson/gds/o186i221/gpu7</code></pre>
</div>
</div>
<div class="paragraph">
<p>Here we have:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>a <code>[global]</code> section which defines key/val pairs for all jobs.</p>
</li>
<li>
<p>a <code>[job]</code> for each GPU, which are all run in parallel.</p>
<div class="ulist">
<ul>
<li>
<p>Each job inherits the values in the <code>[global]</code> section</p>
</li>
<li>
<p>Each job specifies which GPU by index this will run on, and how many threads to use.</p>
</li>
<li>
<p>Each job outputs to its own directory, as to not overflow Lustre&#8217;s maximum 256 files per directory limit</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_benchmark_entrypoint_script"><a class="anchor" href="#_benchmark_entrypoint_script"></a>Benchmark Entrypoint Script</h4>
<div class="paragraph">
<p>Lastly, we have a <code>benchmark.sh</code> shell script which kicks off <code>gdsio</code> using the <code>write.gdsio</code> job file:</p>
</div>
<div class="listingblock">
<div class="title"><code>benchmark.sh</code></div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">#!/bin/bash

# Benchmark script to run gdsio using a .gdsio job file
[[ $# -ne 1 ]] &amp;&amp; echo "Usage: ./benchmark.sh write.gdsio" &amp;&amp; exit 1

# Use a custom cufile.json instead of the default /etc/cufile.json
export CUFILE_ENV_PATH_JSON="/home/ccarlson/gds/cufile.json"

GDSIO="/usr/local/cuda-12.3/gds/tools/gdsio"
JOBFILE=$1
JOB_NAME=${JOBFILE%.gdsio}  # remove .gdsio suffix
THREADS_ARRAY=(8)
RESULTS_DIR="single_node_results"
HOSTNAME=$(hostname)
RESULTS_FILE="${RESULTS_DIR}/${HOSTNAME}_${JOB_NAME}_results.out"

rm -f $RESULTS_FILE
touch $RESULTS_FILE
for THREADS in ${THREADS_ARRAY[@]}; do
  echo "Results for $THREADS threads per GPU:" &gt;&gt; $RESULTS_FILE
  export NUM_GDS_THREADS_PER_GPU=$THREADS
  $GDSIO $JOBFILE &gt;&gt; $RESULTS_FILE
done</code></pre>
</div>
</div>
<div class="paragraph">
<p>All in all, this is what the directory structure looks like for my benchmarks:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-console hljs" data-lang="console">ccarlson@o186i225:~/gds$ tree .
.
├── benchmark.sh
├── cufile.json
├── cufile_logs
│   ├── cufile_116312_2023-12-14.09:19:31.log
│   ├── cufile_117028_2023-12-14.09:27:48.log
│   ├── cufile_117227_2023-12-14.09:29:42.log
│   ├── cufile_118851_2023-12-14.10:22:11.log
│   └── cufile_121697_2023-12-14.11:47:20.log
└── write.gdsio

1 directory, 8 files</code></pre>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_running_benchmarks"><a class="anchor" href="#_running_benchmarks"></a>Running Benchmarks</h3>
<div class="paragraph">
<p>With the above configuration set in place, we can run <code>./benchmark.sh</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-console hljs" data-lang="console">ccarlson@o186i225:~/gds$ ./benchmark.sh
IoType: WRITE XferType: GPUD Threads: 64 DataSetSize: 261804032/134217728(KiB) IOSize: 1024(KiB) Throughput: 6.930582 GiB/sec, Avg_Latency: 9004.751902 usecs ops: 255668 total_time 36.025224 secs</code></pre>
</div>
</div>
</div>
</div>
</div>
</article>
  </div>
</main>
</div>
<footer class="footer">
  <p>Copyright © 2023-2025 Caleb Carlson. All rights reserved.
</footer>
<script id="site-script" src="../../../../_/js/site.js" data-ui-root-path="../../../../_"></script>
<script async src="../../../../_/js/vendor/highlight.js"></script>
  </body>
</html>
